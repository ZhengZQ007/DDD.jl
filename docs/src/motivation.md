# Motivation
`DDD.jl` was created with the aim to make 3D discrete dislocation dynamics research more tractable, transparent and productive.

## Objectives
Dislocation dynamics is notoriously impenetrable due to the wide range of techniques and historically disparate sciences involved in their study. Lowering the barrier to entry and simplifying the workflows of experimental, theoretical and computational researchers will simplify the development of the field. Specifically, our objectives are to develop a codebase that meets the following requirements:

- ease of use
  - simulations are easy to set up
  - interactivity
    - plotting and post-processing
    - data analysis
    - automatic error checking
    - stop and restart capabilities
- ease of development and maintenance
  - readable code
  - metaprogramming
    - macros (compile time execution)
    - generated functions (custom functions generated by the code itself)
  - problem logging
    - clear warnings, errors and debug information
    - easy to add new validations
  - high level abstractions
    - array and matrix operations
    - unicode support
  - code introspection
    - interactive debugger
    - profiling and benchmarking
    - identify bottlenecks, type instabilities before runtime
  - minimal rewriting
    - modular
    - generic functions
    - self-containment
  - easily parallelisable
    - local parallelisation
    - distributed parallelisation
    - GPU parallelisation
- well documented
  - easily add documentation
  - native ``\LaTeX`` support
  - automatically generated
- well developed testing capabilities
  - easily add tests
  - easily interpreted tests
  - test *everything* even logging events such as warnings and errors
- performant
  - use as few languages as possible
  - CUDA may be needed for specialised parallelisation but should not be a requirement
- self-contained
  - no external dependencies
- open-source, shareable, portable
  - publically hosted
  - standardised IO (input-output)
  - plug and play

## Possible Languages for Implementation
Historically, two languages that have reigned supreme in the field of scientific computing `Fortran` and `C`, however with the advent of object-oriented programming, and interpreted languages that list has expanded. Here we offer some likely candidates to build our code. Some of which have been used in the past to create dislocation dynamics codes of different ilks.

### Fortran (f90+)
#### Advantages
It is performant, readable, modular, open-source, highly abstracted, natively parallelisable (compiler dependent), and safe through the use of `intent()` inside functions. Documentation for the language itself is available on the f90 standard practices site and there is a sizeable knowledge base found in StackExchange and the Intel Fortran forums.

#### Disadvantages
It lacks interactivity, metaprogramming (aside from preprocessor macros), and a proper internal standard library. BLAS and LAPACK are as close to a standard library as Fortran gets, but they have to be installed and linked to at compilation time. Furthermore, different compilers break portability, in some cases what is performant code in one compiler is bad code in another. It also has nothing in the way of native testing and documenting, but there are Python tools to do so.

### C
#### Advantages
It is performant, small, modular, open-source and compilers are highly standardised. There is no shortage of documentation for `C` all accross the internet.

#### Disadvantages
On top of lacking what `Fortran` also lacks, it has the added wrinkle of pointer arithmetic. Which is famously the cause of most `C` bugs. The best case scenario for such bugs lead to obvious problems like segmentation faults and `NaN` values. However, more insidious and opaque bugs are not uncommon in complex code, examples include pointer dereferencing, function side effects and memory leaks. Such bugs are hard to track, reproduce and at times catastrophic. Some very well-known bugs and exploits in commercial software such as Windows have been thanks to memory leaks and pointer dereferencing, often going undiscovered for years and through multiple versions. `C` also doesn't offer anything in the way of abstraction other than structures.

### C++
#### Advantages
It has an extensive standard library of optimised algorithms and data structures, all of which are excellently documented. It is open-source and its compilers are also highly standardised (though not as much as `C`). It also offers serious metaprogramming capabilities, and can be made to be very performant *if used correctly*, sometimes more so than a na√Øve C implementation. There are extensive knowledge bases of C++ but the problem is often in deciphering how one may adapt the posted solution to their specific situation.

#### Disadvantages
It is *extremely* is verbose, very difficult to learn and use correctly, opaque and unintuitive (`new` v.s. `malloc()`, `del` vs `free()`, namespaces). It mitigates some of the problems of C at the cost of runtime performance and added program complexity. It also tends to make debugging user defined code more difficult because one has to trawl through verbose, complicated syntax. It also requires external libraries to be installed and linked to during compilation.

### Python
#### Advantages
The golden child of interpreted languages is readable, easy to use, open-source, standardised, portable and interactive. It also has an even more extensive standard library than `C++`. Its vibrant package ecosystem ensures there are packages for every need and frees the user from worrying about external dependencies because they are taken care of by the package installer either automatically or by printing the command required to install the dependency. It has native documentation, testing and benchmarking capabilities. The language has an extremely high level of abstraction and is rapidly evolving, improving and expanding. Package documentation tends to be the gold standard for documentation across all languages by virtue of the sheer number of users and contributors. There is also an extensive knowledge base throughout the internet where solutions to problems have most likely already been posted about and found, if not, one can make a post and have their question answered rather quickly.

#### Disadvantages
It is not performant without serious modification like using `Cython` or by standard-breaking practices to use the JIT (just in time compiler) offered by `numba`. Packages such as `numpy` and `scipy` help in this regard, but more often than not, the number crunching is done via calls to `C`, `CUDA` and `Fortran` routines through wrappers or direct external calls. Python can also get somewhat verbose, particularly when using a few packages where namespaces must be distinguished by aliases. Standalone executables are much larger than they would be in other languages.

### Matlab
#### Advantages
Is readable, easy to use, standardised and interactive. It has native testing, documentation and benchmarking capabilities. The documentation for in-built functions is excellent. It offers limited object oriented capabilities, usually more than enough.

#### Disadvantages
It is closed-source and proprietary. Worse, many of the toolboxes and specialised features are not standard and require additional purchase. Furthermore, the knowledge base for specific questions is limited to the Mathworks forums where only people with Mathworks accounts may post. Increasingly, `Matlab` offers less and less in comparison to `Python`. Pretty much all of the performance issues are shared by both languages, but `Python` is free, open-source and has a massive community developing packages and adding functionality.

### Julia
#### Advantages
Every advantage that `Python` offers is also offered by `Julia`, from the standard library to benchmarking and testing. Its package ecosystem and user base is nowhere near as large as `Python`'s, but it offers the same functionality.

Unlike any of the other languages we mentioned, `Julia` is a JIT (just in time) compiled language, just like `Python` when using `numba`. So it offers `C` and `Fortran`-like performance after a function has been executed once. It offers the same level of abstraction as `Python` and `Matlab` while keeping similar or even equivalent[^1 In most cases, the abstractions have a cost-benefit associated with using them, using introspection tools is recommended if performance is critical. Sometimes they outperform less abstracted implementations, but others a non-abstracted implementation is better.] performance to `Fortran` and `C`.

One of the advantages of object-oriented code is reusability and expandability. Function dispatch in object-oriented languages depends on the function's class. However, `Julia`'s multiple dispatch, type system, and JIT compilation takes code reusability to another level by letting functions specialise depending on the types of their arguments. This means that one can expand functions defined anywhere in the code by declaring them for new types. This means developers can write generic functions that can be expanded by users as they see fit. A concrete example we use in `DDD.jl` is in constructing dislocation loops. Where new types of loops or even special dislocation structures don't need their own data structure, one can simply declare a new constructor for a new type of loop and it will be called using the same user-interface.

Furthermore, `Julia` can be used as both, a statically typed or dynamically typed language. If one wants performance, one gets performance by annotating types[^2 Types do not have to be known by the user before runtime, they can be given parametrically and the compiler will use the argument's type during runtime to compile a specialised function. This lets programs be generically typed without sacrificing performance or adding verbosity.] and writing well-defined code. If one wants to use `Julia` interactively like `Python` or `Matlab`, that works too. And the compiler will do its best to ensure the code is performant.

Another aspect that `Julia` offers that none of the others do is the ability to look at the different stages of compilation. This lets developers and users identify areas where the code might suffer a runtime bottleneck before even running it. There are also extensive profiling, debugging and benchmarking tools that provide timing and memory allocation information. Out of the languages mentioned, `Julia` is the easiest to write performant code in.

If this weren't enough, there is also native support for CPU and GPU parallelisation both local and distributed, as well as the ability to call external languages with a single interface. Its metaprogramming capabilities are on par with `C++` but much more concise and less impactful on compilation time.

#### Disadvantages
Multiple dispatch can be abused by new users and may negatively impact performance. Precompilation time for packages and the "time to first plot" can be relatively long.

It is a new language, things are changing rapidly and backwards compatibility may not always be guaranteed. There are also features that are experimental and subject to change, deprecation and removal. For example, 1.4 CPU parallelisation is experimental as well as the `@simd` macro for inner loop performance.

A side effect of the incredibly powerful documenting system of `Julia` is that one can go to where intrinsic functions are implemented and one is free to change them. However this also means that if a user wants to extend an intrinsic method they can use the documentation to navigate to where it is defined and see how it is implemented so they may extend it for their use case.
